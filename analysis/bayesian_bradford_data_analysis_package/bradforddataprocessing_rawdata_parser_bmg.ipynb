{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "<br>\n",
    "This notebook is the first step in a workflow that deals with Bradford Protein Quantification 96x well plate reader data:\n",
    "\n",
    "1. Exploratory data analysis.\n",
    "2. Cleaning the data to remove absorbance values that are outside the linear range of the instrument\n",
    "3. Parsing and exporting both the calibrant and sample data into the processed_data_files directory preparatory to downstream analysis\n",
    "\n",
    "Alex Perkins 16th November 2021\n",
    "a.j.p.perkins@sms.ed.ac.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Preparation ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC3 v3.11.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import pymc3 as pm\n",
    "from pymc3 import HalfCauchy, Model, Normal, glm, plot_posterior_predictive_glm, sample\n",
    "\n",
    "print(f\"Running on PyMC3 v{pm.__version__}\")\n",
    "\n",
    "import arviz as az\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Import curve fitting package from scipy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# import os\n",
    "import os, sys, shutil\n",
    "\n",
    "from experiment_specific_config import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell just deals with reading the data file in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['134709_221009_OT2_BRADFORD.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_180/1813348041.py:44: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  raw_data = pd.read_csv(csv_list[0], header=None, error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "\n",
    "move_file = False\n",
    "\n",
    "##################################################################\n",
    "# define error handler\n",
    "class UnAcceptedValueError(Exception):   \n",
    "    def __init__(self, data):    \n",
    "        self.data = data\n",
    "    def __str__(self):\n",
    "        return repr(self.data)\n",
    "\n",
    "####################################################################\n",
    "# gets all items in directory\n",
    "items = os.listdir(\".\")\n",
    "\n",
    "# lists all .csv\n",
    "csv_list = []\n",
    "\n",
    "try:\n",
    "    for names in items:\n",
    "        if names.endswith(\".CSV\") | names.endswith(\".csv\"):\n",
    "            csv_list.append(names)\n",
    "\n",
    "except:\n",
    "    print(\"Couldn't find any csv files\")\n",
    "\n",
    "try:\n",
    "    if(len(csv_list) > 1):\n",
    "        raise UnAcceptedValueError(\"More than 1x .CSV file in the directory\");\n",
    "except UnAcceptedValueError as e:\n",
    "    print (\"Received error:\", e.data)\n",
    "    # kills the process\n",
    "    quit()\n",
    "##########################################################################################\n",
    "print(csv_list)\n",
    "\n",
    "\n",
    "\n",
    "experiment_name = csv_list[0]\n",
    "\n",
    "\n",
    "#import dataset as dataframe\n",
    "raw_data = pd.read_csv(csv_list[0], header=None, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bradford_index_list =[]\n",
    "\n",
    "# iterate over the rows\n",
    "for i,row in enumerate(raw_data.iloc[:,0]):\n",
    "    \n",
    "    #if string\n",
    "    if isinstance(row, str):\n",
    "        \n",
    "        #if first 7 characters spell bradford\n",
    "        if row[:8] == \"Bradford\":\n",
    "            # append the row index to the list\n",
    "            bradford_index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/src\n"
     ]
    }
   ],
   "source": [
    "parsed_data = pd.DataFrame(columns=[\"index\", \"absorbance\", \"measurement\"])\n",
    "\n",
    "\n",
    "for first_index in bradford_index_list:\n",
    "    \n",
    "    last_index = first_index + 10\n",
    "    \n",
    "    individual_slice = raw_data.iloc[first_index:last_index, :].reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    for i, row in individual_slice.iterrows():\n",
    "        \n",
    "        if i >= 2 | i < 10:\n",
    "            \n",
    "            selected_row = individual_slice.iloc[i, :]\n",
    "            \n",
    "            plate_letter_row = selected_row[0]\n",
    "            \n",
    "            data = selected_row[1:-1].reset_index()\n",
    "            \n",
    "            data[\"index\"] = plate_letter_row + data[\"index\"].astype(str)\n",
    "            data[\"measurement\"] = selected_row.iloc[-1]\n",
    "            data = data.set_axis([\"index\", \"absorbance\", \"measurement\"], axis=1, copy=False)\n",
    "            \n",
    "            parsed_data = pd.concat([parsed_data, data], ignore_index=True)\n",
    "            \n",
    "#######################################################################\n",
    "\n",
    "print(os.getcwd())\n",
    "path = \"/src/processed_data_files/\"\n",
    "# make directory for sticking the output in\n",
    "if os.path.isdir(path) == False:\n",
    "    os.mkdir(path, mode=0o777)\n",
    "    \n",
    "    \n",
    "# now that the dataset has been read in, move it into the processed_data_files file for neatness.\n",
    "if 1 == move_file:\n",
    "    shutil.move(csv_list[0], path)\n",
    "\n",
    "# navigate into the directory for future processed_data_files storage\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "parsed_data.to_csv(experiment_name+\"_parsed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date= raw_data.iloc[1,1]\n",
    "\n",
    "\n",
    "\n",
    "#data = raw_data.iloc[9:,:]\n",
    "\n",
    "#data.columns = data.iloc[0,:]\n",
    "\n",
    "#data = data.iloc[1:,:3]\n",
    "\n",
    "#data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/src/processed_data_files\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "\n",
    "print(os.getcwd())\n",
    "path = \"/src/output/\"\n",
    "# make directory for sticking the output in\n",
    "if os.path.isdir(path) == False:\n",
    "    os.mkdir(path, mode=0o777)\n",
    "    \n",
    "    \n",
    "# now that the dataset has been read in, move it into the output file for neatness.\n",
    "if 1 == move_file:\n",
    "    shutil.move(csv_list[0], path)\n",
    "\n",
    "# navigate into the directory for future plot storage\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Enviroment Setup ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define limits for linear range of platereader\n",
    "upper_limit = 0.75\n",
    "lower_limit = 0.45\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the raw calibrant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Looking at the raw values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Bradford:595'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m calibrants \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:num_of_calibrant_wells,[\u001b[38;5;241m2\u001b[39m]]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# reshape\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m calibrants \u001b[38;5;241m=\u001b[39m \u001b[43mcalibrants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m calibrants_np \u001b[38;5;241m=\u001b[39m calibrants\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     13\u001b[0m calibrants_np_2d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(calibrants_np, (\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(calibrants_np)\u001b[38;5;241m/\u001b[39mnum_calibrant_replicates), num_calibrant_replicates))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py:6245\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6238\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6239\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   6240\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   6241\u001b[0m     ]\n\u001b[1;32m   6243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6244\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6245\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6248\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py:446\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py:348\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 348\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py:527\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    525\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 527\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    530\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    227\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py:170\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Bradford:595'"
     ]
    }
   ],
   "source": [
    "# real concs in wells. Stocks in ug/ml diluted by 20x\n",
    "calibrant_range = [\"0\",\"50\",\"75\",\"100\", \"125\", \"150\", \"175\",\"200\"]\n",
    "\n",
    "num_of_calibrant_wells = num_calibrant_replicates * len(calibrant_range)\n",
    "\n",
    "calibrants = data.iloc[:num_of_calibrant_wells,[2]]\n",
    "\n",
    "\n",
    "# reshape\n",
    "calibrants = calibrants.astype(float)\n",
    "calibrants_np = calibrants.to_numpy()\n",
    "\n",
    "calibrants_np_2d = np.reshape(calibrants_np, (int(len(calibrants_np)/num_calibrant_replicates), num_calibrant_replicates))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "ax1 = sns.heatmap(calibrants_np_2d, vmin = lower_limit, vmax = upper_limit, annot=True, cmap=\"coolwarm\")\n",
    "ax1.set_ylabel(\"BSA ug/Ml\")\n",
    "ax1.set_title(\"Calibrant Raw Absorbances.\")\n",
    "ax1.set_xlabel(\"Replicate #\")\n",
    "plt.yticks(np.arange(8)+0.5,calibrant_range, rotation=0, fontsize=\"10\")\n",
    "\n",
    "plt.savefig(\"BSA_absorbances_heat.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Reorganising Calibrant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segregate the calibrant samples.\n",
    "calibrants_df = pd.DataFrame(calibrants_np_2d, columns=[\"Rep1\", \"Rep2\", \"Rep3\",\"Rep4\", \"Rep5\"], index=calibrant_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to use it later\n",
    "def reorg_calibrants_for_GLM(input_data):\n",
    "    output_for_glm = pd.DataFrame(columns=['Concentration', 'Absorbance'])\n",
    "    for idx, row in input_data.iterrows():\n",
    "\n",
    "\n",
    "        r_list = [row['Rep1'],row['Rep2'],row['Rep3'],row['Rep4'],row['Rep5']]\n",
    "\n",
    "        place_holder_df = pd.DataFrame()\n",
    "\n",
    "        place_holder_df['Absorbance'] = r_list\n",
    "        place_holder_df['Concentration'] = np.float(idx)\n",
    "\n",
    "        output_for_glm = output_for_glm.append(place_holder_df)\n",
    "\n",
    "    output_for_glm =output_for_glm.reset_index(drop=True)\n",
    "    print(output_for_glm)\n",
    "\n",
    "    output_for_glm.plot.scatter(x='Absorbance', y='Concentration')\n",
    "    \n",
    "    return output_for_glm\n",
    "\n",
    "calibrants_for_GP = reorg_calibrants_for_GLM(calibrants_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Filter the calibrants and only keep those within the linear range  (0.75 - 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################   Subset Standards aborbance values that fall within the linear range (0.75 - 0.45)\n",
    "\n",
    "calibrants_for_GP = calibrants_for_GP.loc[(calibrants_for_GP[\"Absorbance\"] >= lower_limit) & (calibrants_for_GP[\"Absorbance\"] <= upper_limit)]\n",
    "calibrants_for_GP = calibrants_for_GP.reset_index(drop=True)\n",
    "print(calibrants_for_GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step: 4 Defining the absorbance of each concentration as a gaussian.\n",
    "\n",
    "This allows us to store the mean concentration and it's error as a function and calculate the probabilities on demand.\n",
    "\n",
    "Lets assume that the technical error of the absorbance measurements are normally distributed\n",
    "\n",
    "1. We calculate the mean and the standard deviation for each absorbance triplicate.\n",
    "2. We define a gaussian sampling function so we can easily sample and return a granular array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# calculate the mean of each triplicate\n",
    "calibrants_df[\"Mean\"] = calibrants_df.mean(axis=1)\n",
    "# calculate the variance of each triplicate\n",
    "calibrants_df[\"σ\"] = calibrants_df.iloc[:,:3].std(axis=1)\n",
    "\n",
    "calibrants_df_avg = calibrants_df[[\"Mean\", \"σ\"]]\n",
    "\n",
    "\n",
    "def sample_gaussian(mu, sigma):\n",
    "    \n",
    "    # define the x range: mean - 4*sigma and mean + 4*sigma. increments = mean/1000\n",
    "    x = np.arange((mu-(4*sigma)),(mu+(4*sigma)), mu/1000)\n",
    "    \n",
    "    # use the norm.pdf (probability density function) to sample and return the array.\n",
    "    return norm.pdf(x, mu, sigma)\n",
    "\n",
    "# do it for each calibrant. Not currently stored.\n",
    "for idx, row in calibrants_df_avg.iterrows():\n",
    "    sample_gaussian(calibrants_df.loc[idx][\"Mean\"], calibrants_df.loc[idx][\"σ\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having got our function, lets plot all the gaussians together and have a wee look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_gaussians(mu, sigma, bins, index):\n",
    "    \n",
    "    # define the x range: mean - 4*sigma and mean + 4*sigma. increments = mean/1000\n",
    "    x = np.arange((mu-(4*sigma)),(mu+(4*sigma)), mu/1000)\n",
    "    \n",
    "    # plot the function\n",
    "    plt.plot(x, norm.pdf(x, mu, sigma),  label=str(idx))\n",
    "    \n",
    "\n",
    "# do it for every calibrant and produce the plot afterwards\n",
    "for idx, row in calibrants_df.iterrows():\n",
    "    print_all_gaussians(calibrants_df.loc[idx][\"Mean\"], calibrants_df.loc[idx][\"σ\"], 10000, idx)\n",
    "\n",
    "# just setting the labels and ticks\n",
    "plt.tick_params(left=False,\n",
    "                bottom=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=True)\n",
    "\n",
    "plt.title('Calibrant Absorbance Probability Functions')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Arbitary Absorbance Units')\n",
    "\n",
    "plt.legend(title='μg/ml', loc=(1.03, 0.3))\n",
    "\n",
    "plt.savefig('Calibrant Absorbance Probabilty Functions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Looking at the raw sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilution_data = data.iloc[num_of_calibrant_wells:,:]\n",
    "dilution_data = dilution_data.reset_index(drop=True)\n",
    "dilution_data['Raw Data (595)'] = pd.to_numeric(dilution_data['Raw Data (595)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiment_replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_slicer = num_experiment_replicates * len(dilutions)\n",
    "protein_slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilution_dict = {}\n",
    "\n",
    "proteins_backslice = 0\n",
    "proteins_frontslice = protein_slicer\n",
    "\n",
    "for p in unknown_proteins:\n",
    "    \n",
    "    # initalise the upper key of the dict\n",
    "    dilution_dict[p] = {}\n",
    "    \n",
    "    # get all of the wells relevent to that protein using the slices and reset the index\n",
    "    working_slice = dilution_data.iloc[proteins_backslice:proteins_frontslice,:]\n",
    "    working_slice = working_slice.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    #initalise the slicers for going through the dilutions\n",
    "    dilutions_backslice = 0\n",
    "    dilutions_frontslice = num_experiment_replicates\n",
    "    \n",
    "    # iterate through the dilutions list\n",
    "    for d in dilutions:\n",
    "        \n",
    "        # actually assign the data\n",
    "        dilution_dict[p][d] = working_slice.iloc[dilutions_backslice : dilutions_frontslice]\n",
    "        \n",
    "        # update the slicers\n",
    "        dilutions_backslice = dilutions_frontslice\n",
    "        dilutions_frontslice = dilutions_frontslice + num_experiment_replicates\n",
    "        \n",
    "\n",
    "    # update the slicers\n",
    "    proteins_backslice = proteins_frontslice\n",
    "    proteins_frontslice = proteins_frontslice + protein_slicer\n",
    "    \n",
    "dilution_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilution_dict['AA tRNA Synthetases']['50']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make directory for sticking the heat maps into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "path = \"/src/output/sampleheatmaps/\"\n",
    "\n",
    "# make directory for sticking the output in\n",
    "if os.path.isdir(path) == False:\n",
    "    os.mkdir(path, mode=0o777)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate through the dilution dictionary and make the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Reorganising Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "#initalise empty tidy dataframe\n",
    "dilution_df = pd.DataFrame(columns= [\"DilutionX\", \"Absorbance\", \"ProteinMix\"])\n",
    "\n",
    "\n",
    "for p_id, p_data in dilution_dict.items():\n",
    "    \n",
    "    # p_id is the mixture name. e.g. AA tRNA Synthatases\n",
    "    # p_data contains a dictionary containing all of the dilutions. e.g. '100': dataframe with three replicates\n",
    "\n",
    "    \n",
    "    protein_list = []\n",
    "    \n",
    "    for dilution in p_data:\n",
    "        \n",
    "        # dilution is just the key. i.e. '100'\n",
    "        \n",
    "        # use the key to look up all the absorbance values for the replicates of that dilution.\n",
    "        # make them into a list and append on the 'master list' for that protein mixture\n",
    "        \n",
    "        sample_data = list(p_data[dilution]['Raw Data (595)'])\n",
    "        protein_list.append(sample_data)\n",
    "        \n",
    "    \n",
    "    \n",
    "    plot_dict = {}\n",
    "    \n",
    "    # using the index and the dilution dictionary keys, populate the plot dict with the absorbances lists generated above.\n",
    "    for i,d in enumerate(dilutions):\n",
    "        \n",
    "        plot_dict[d] = protein_list[i]\n",
    "        \n",
    "    # use the dictionary to make a DataFrame and transpose it\n",
    "        \n",
    "    plot_df = pd.DataFrame(plot_dict).T\n",
    "    \n",
    "    \n",
    "    # make heatmap\n",
    "    \n",
    "    sns.heatmap(plot_df, vmin = lower_limit, vmax = upper_limit, annot=True, cmap=\"coolwarm\")\n",
    "\n",
    "    plt.ylabel(\"Dilution Factor\")\n",
    "    \n",
    "    title = \"Absorbances of Diluted \" + p_id\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Replicate #\")\n",
    "    plt.yticks(np.arange(plot_df.shape[0])+0.5, dilutions, rotation=0, fontsize=\"10\")\n",
    "\n",
    "    figname = p_id + \"_\" + dilution + \".png\"\n",
    "\n",
    "    plt.savefig(figname)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ######### retranspose back so that the melt works\n",
    "    plot_df = plot_df.T\n",
    "    \n",
    "    # melt for tidy data\n",
    "    melted = pd.melt(frame = plot_df,\n",
    "                    var_name = 'DilutionX',\n",
    "                    value_name = 'Absorbance'\n",
    "                    )\n",
    "    \n",
    "    \n",
    "    melted['ProteinMix'] = p_id\n",
    "    \n",
    "    dilution_df = pd.concat([dilution_df, melted])\n",
    "    \n",
    "    \n",
    "dilution_df = dilution_df.reset_index(drop=True)\n",
    "    \n",
    "print(dilution_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Filter the sample data and only keep those within the linear range  (0.75 - 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################   Subset Standards aborbance values that fall within the linear range (0.75 - 0.45)\n",
    "\n",
    "acceptable_data = dilution_df.loc[(dilution_df[\"Absorbance\"] >= lower_limit) & (dilution_df[\"Absorbance\"] <= upper_limit)]\n",
    "\n",
    "acceptable_data = acceptable_data.reset_index(drop=True)\n",
    "print(acceptable_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the parsed calibrant and sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check if '/processed_data_files' exists. If not, create it and navigate inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "path_processed_data = \"/src/processed_data_files/\"\n",
    "# make directory for sticking the processed data in\n",
    "if os.path.isdir(path_processed_data) == False:\n",
    "    os.mkdir(path_processed_data, mode=0o777)\n",
    "\n",
    "# navigate into the path_processed_data directory for data storage\n",
    "os.chdir(path_processed_data)\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Export both calibrant and sample data into processed_data_files as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrants_for_GP.to_csv(\"parsed_calibrant_data.csv\")\n",
    "acceptable_data.to_csv(\"tidy_sample_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate back into the root directory for neatness\n",
    "os.chdir(\"/src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
