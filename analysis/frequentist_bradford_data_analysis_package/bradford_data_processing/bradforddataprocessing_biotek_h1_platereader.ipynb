{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You might have to open the raw data file in libra office and merge the dilimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['154253_230202_OT2_BRADFORD.csv', 'Consensus_concentration.csv']\n",
      "Received error: More than 1x .CSV file in the directory\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "# Import curve fitting package from scipy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# import os\n",
    "import os, sys, shutil\n",
    "\n",
    "##################################################################\n",
    "# define error handler\n",
    "class UnAcceptedValueError(Exception):   \n",
    "    def __init__(self, data):    \n",
    "        self.data = data\n",
    "    def __str__(self):\n",
    "        return repr(self.data)\n",
    "\n",
    "####################################################################\n",
    "# gets all items in directory\n",
    "items = os.listdir(\".\")\n",
    "\n",
    "\n",
    "# lists all .csv\n",
    "csv_list = []\n",
    "for names in items:\n",
    "    if names.endswith(\".csv\"):\n",
    "        csv_list.append(names)\n",
    "print(csv_list)\n",
    "try:\n",
    "    if(len(csv_list) > 1):\n",
    "        raise UnAcceptedValueError(\"More than 1x .CSV file in the directory\");\n",
    "except UnAcceptedValueError as e:\n",
    "    print (\"Received error:\", e.data)\n",
    "    # kills the process\n",
    "    quit()\n",
    "##########################################################################################\n",
    "#import dataset as dataframe\n",
    "\n",
    "raw_data = pd.read_csv(csv_list[0], sep=',', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1      2      3      4      5                         6      7      8   \\\n",
      "0  1.422  1.420  1.459  0.595  0.601                     0.607  0.649  0.595   \n",
      "1  1.042  1.076  1.077  1.383  1.373                     1.386  1.377  1.374   \n",
      "2  0.778  0.801  0.800  1.720  1.705                      1.73  1.721  1.735   \n",
      "3  1.929  1.923  1.920  1.937  1.945  Corrected [Bradford:595]    NaN    NaN   \n",
      "4  2.137  2.139  2.148  2.143  2.144  Corrected [Bradford:595]    NaN    NaN   \n",
      "5  2.319  2.306  2.307  2.306  2.378  Corrected [Bradford:595]    NaN    NaN   \n",
      "6  2.489  2.512  2.499  2.495  2.462  Corrected [Bradford:595]    NaN    NaN   \n",
      "7  2.567  2.564  2.552  2.555  2.559  Corrected [Bradford:595]    NaN    NaN   \n",
      "\n",
      "                         9   10  11  12  \n",
      "0  Corrected [Bradford:595] NaN NaN NaN  \n",
      "1  Corrected [Bradford:595] NaN NaN NaN  \n",
      "2  Corrected [Bradford:595] NaN NaN NaN  \n",
      "3                       NaN NaN NaN NaN  \n",
      "4                       NaN NaN NaN NaN  \n",
      "5                       NaN NaN NaN NaN  \n",
      "6                       NaN NaN NaN NaN  \n",
      "7                       NaN NaN NaN NaN  \n"
     ]
    }
   ],
   "source": [
    "# get the row index of the cell that contains the string \"Corrected [Bradford:595]\"\n",
    "row_index = raw_data.index[raw_data.loc[:,0]==\"Corrected [Bradford:595]\"][0]\n",
    "\n",
    "corrected_data = raw_data.iloc[row_index+2: row_index + 10, 1 : 13].reset_index(drop=True)\n",
    "print(corrected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1      2      3      4      5\n",
      "0  1.422  1.420  1.459  0.595  0.601\n",
      "1  1.042  1.076  1.077  1.383  1.373\n",
      "2  0.778  0.801  0.800  1.720  1.705\n",
      "3  1.929  1.923  1.920  1.937  1.945\n",
      "4  2.137  2.139  2.148  2.143  2.144\n",
      "5  2.319  2.306  2.307  2.306  2.378\n",
      "6  2.489  2.512  2.499  2.495  2.462\n",
      "7  2.567  2.564  2.552  2.555  2.559\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# hot fix to deal with the parser not being able to parse \"blank wells\".\n",
    "# remove at a later date\n",
    "\n",
    "calibrants = corrected_data.iloc[:,0:5]\n",
    "print(calibrants)\n",
    "print(type(calibrants.iloc[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1      2      3      4      5\n",
      "0  0.778  0.801  0.800  0.595  0.601\n",
      "1  1.042  1.076  1.077  1.383  1.373\n",
      "2  1.422  1.420  1.459  1.720  1.705\n",
      "3  1.929  1.923  1.920  1.937  1.945\n",
      "4  2.137  2.139  2.148  2.143  2.144\n",
      "5  2.319  2.306  2.307  2.306  2.378\n",
      "6  2.489  2.512  2.499  2.495  2.462\n",
      "7  2.567  2.564  2.552  2.555  2.559\n"
     ]
    }
   ],
   "source": [
    "new_low = calibrants.iloc[0,0:3].copy()\n",
    "new_high = calibrants.iloc[2,0:3].copy()\n",
    "\n",
    "\n",
    "calibrants.iloc[0,0:3] = new_high\n",
    "calibrants.iloc[2,0:3] = new_low\n",
    "\n",
    "print(calibrants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# reshape\n",
    "\n",
    "calibrants_np = calibrants.to_numpy()\n",
    "\n",
    "replicates = 5\n",
    "\n",
    "# real concs in wells. Stocks in ug/ml diluted by 20x\n",
    "calibrant_range = [\"0\",\"500\",\"750\",\"1000\", \"1250\", \"1500\", \"1750\",\"2000\"]\n",
    "\n",
    "#calibrants_np_2d = np.reshape(calibrants_np, (int(len(calibrants_np)/replicates), replicates))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "ax1 = sns.heatmap(calibrants_np, annot=True, cmap=\"coolwarm\")\n",
    "ax1.set_ylabel(\"BSA ug/Ml\")\n",
    "ax1.set_title(\"Calibrant Raw Absorbances.\")\n",
    "ax1.set_xlabel(\"Replicate #\")\n",
    "plt.yticks(np.arange(8)+0.5,calibrant_range, rotation=0, fontsize=\"10\")\n",
    "\n",
    "plt.savefig(\"output/BSA_absorbances_heat.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "calibrants_df = pd.DataFrame(calibrants_np, columns=[\"Rep1\", \"Rep2\", \"Rep3\", \"Rep4\", \"Rep5\"], index=calibrant_range)\n",
    "\n",
    "calibrants_df[\"Mean\"] = calibrants_df.mean(axis=1)\n",
    "calibrants_df[\"SEM\"] = calibrants_df.iloc[:,:3].sem(axis=1)\n",
    "\n",
    "calibrants_df_avg = calibrants_df[[\"Mean\", \"SEM\"]]\n",
    "\n",
    "#plot \n",
    "\n",
    "x = calibrants_df_avg.index\n",
    "y = calibrants_df_avg['Mean']\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.errorbar(x,y, yerr=calibrants_df_avg['SEM'], fmt=\"|\", color=\"r\")\n",
    "\n",
    "plt.title(\"Absorbance of BSA Standards\")\n",
    "plt.ylabel(\"Absorbance\")\n",
    "plt.xlabel(\"BSA ug/Ml\")\n",
    "plt.savefig(\"output/BSA_Standard_Absorbances_scatter.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calibrant_range' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e94f6967c721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# calibrant concs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcalibrant_range_numerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcalibrant_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalibrant_range_numerical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# fit curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calibrant_range' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# calibrant concs\n",
    "calibrant_range_numerical = [float(ele) for ele in calibrant_range]\n",
    "print(calibrant_range_numerical)\n",
    "\n",
    "# fit curves\n",
    "#function for looping?\n",
    "model = LinearRegression()\n",
    "# fitc data in to array and reverse the order\n",
    "x = np.array(calibrants_df_avg[\"Mean\"]).reshape(-1,1)\n",
    "\n",
    "# List of nM concs into array\n",
    "y = np.array(calibrant_range_numerical).reshape(-1,1)\n",
    "\n",
    "x = x.reshape(-1,1)\n",
    "\n",
    "# Fit\n",
    "model.fit(x,y)\n",
    "r_sq = model.score(x, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "\n",
    "#Plot\n",
    "plt.scatter(x, y, color='g')\n",
    "plt.plot(x, model.predict(x), color='k')\n",
    "\n",
    "textstr ='r²: ' +str(round(r_sq,2))\n",
    "plt.text(calibrants_df_avg[\"Mean\"].min(), calibrant_range_numerical[-1], textstr, color='r', fontsize=10)\n",
    "\n",
    "plt.title('Standard Curve')\n",
    "plt.xlabel('Arbitrary Absorbance Units')\n",
    "plt.ylabel('BSA μg/Ml')\n",
    "plt.savefig(\"output/BSA_Standard_Curve.png\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corrected_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7863d4e86bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreplicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msample_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrected_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#new_low = corrected_data.iloc[0,:].copy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corrected_data' is not defined"
     ]
    }
   ],
   "source": [
    "# samples mean & sem\n",
    "\n",
    "replicates = 3\n",
    "\n",
    "sample_data = corrected_data.iloc[:3,5:8]\n",
    "\n",
    "#new_low = corrected_data.iloc[0,:].copy()\n",
    "#new_high = corrected_data.iloc[2,:].copy()\n",
    "\n",
    "#sample_data.iloc[0,:] = new_high\n",
    "#sample_data.iloc[2,:] = new_low\n",
    "\n",
    "\n",
    "sample_data = sample_data.values\n",
    "\n",
    "sample_list =[\"20x\",\"40x\",\"100x\"]\n",
    "\n",
    "sample_data = pd.DataFrame(sample_data, columns=[\"Rep1\", \"Rep2\", \"Rep3\"], index = sample_list).astype(float)\n",
    "sns.set()\n",
    "\n",
    "\n",
    "sns.heatmap(sample_data, annot=True, cmap=\"coolwarm\")\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel(\"Dilution Factor\")\n",
    "plt.title(\"Absorbances of Diluted samples\")\n",
    "plt.xlabel(\"Replicate #\")\n",
    "plt.yticks(np.arange(sample_data.shape[0])+0.5, sample_list, rotation=0, fontsize=\"10\")\n",
    "plt.savefig(\"output/Sample_Absorbances_heat.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2ec938c8053c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Mean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SEM\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msamples_df_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SEM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sample_data[\"Mean\"] = sample_data.mean(axis=1)\n",
    "sample_data[\"SEM\"] = sample_data.iloc[:,:3].sem(axis=1)\n",
    "\n",
    "\n",
    "samples_df_avg = sample_data[[\"Mean\", \"SEM\"]]\n",
    "\n",
    "ax3 = samples_df_avg.plot(kind=\"bar\", yerr=\"SEM\", legend=False)\n",
    "\n",
    "\n",
    "ax3.set_title(\"Mean Absorbances of Sample Dilutions\")\n",
    "ax3.set_ylabel(\"Absorbance\")\n",
    "ax3.set_xlabel(\"Dilution Factor\")\n",
    "plt.xticks(np.arange(samples_df_avg.shape[0]),sample_list, rotation=0, fontsize=\"10\")\n",
    "plt.savefig(\"output/Sample_Absorbances_Bar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c82cccbe60dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### subset samples that don't fall in linear range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macceptable_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#get the index again for the names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_data' is not defined"
     ]
    }
   ],
   "source": [
    "#### subset samples that don't fall in linear range\n",
    "acceptable_samples = sample_data\n",
    "\n",
    "\n",
    "#get the index again for the names\n",
    "acceptable_samples_list = acceptable_samples.index\n",
    "print(acceptable_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# convert samples\n",
    "predicted_ug_per_ml = model.predict(np.array(acceptable_samples.iloc[:,:3]).reshape(-1,1))\n",
    "predicted_ug_per_ml = np.reshape(predicted_ug_per_ml,(int(len(predicted_ug_per_ml)/replicates), replicates))\n",
    "predicted_ug_per_ml = pd.DataFrame(predicted_ug_per_ml, columns=[\"Rep1\", \"Rep2\", \"Rep3\"], index = acceptable_samples_list)\n",
    "\n",
    "print(predicted_ug_per_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#account for the dilutions\n",
    "numrows = predicted_ug_per_ml.shape[0]\n",
    "\n",
    "print(\"Raw dataset:\")\n",
    "print(predicted_ug_per_ml)\n",
    "print(\" \")\n",
    "\n",
    "for index, row in predicted_ug_per_ml.iterrows():\n",
    "    # get the dilution factor from the index\n",
    "    ind = str(index)\n",
    "    ind = ind[:-1]\n",
    "    ind = int(ind)\n",
    "\n",
    "    print(\"Multiplying row \" + str(index) +  \" by dilution factor: \"+ str(ind))\n",
    "    \n",
    "    predicted_ug_per_ml.loc[index, \"Rep1\"] = predicted_ug_per_ml.loc[index, \"Rep1\"]*ind\n",
    "    predicted_ug_per_ml.loc[index, \"Rep2\"] = predicted_ug_per_ml.loc[index, \"Rep2\"]*ind\n",
    "    predicted_ug_per_ml.loc[index, \"Rep3\"] = predicted_ug_per_ml.loc[index, \"Rep3\"]*ind\n",
    "\n",
    "# get list of row indexes\n",
    "\n",
    "print(\" \")\n",
    "print(\"dataset multipled by dilution factor\")\n",
    "print(\" \")\n",
    "\n",
    "\n",
    "print(predicted_ug_per_ml)\n",
    "\n",
    "# Use that to perform that calculations just on the right columns\n",
    "# recalculate mean and SEM\n",
    "\n",
    "predicted_ug_per_ml['ug/ml'] = predicted_ug_per_ml.loc[list(predicted_ug_per_ml.index),[\"Rep1\", \"Rep2\",\"Rep3\"]].mean(axis=1)\n",
    "predicted_ug_per_ml['ug/ml SEM'] = predicted_ug_per_ml.loc[list(predicted_ug_per_ml.index),[\"Rep1\", \"Rep2\",\"Rep3\"]].sem(axis=1)\n",
    "\n",
    "print(\" \")\n",
    "print(\"dataset in ug/ml\")\n",
    "print(\" \")\n",
    "\n",
    "print(predicted_ug_per_ml[['ug/ml','ug/ml SEM']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#get index to use and names\n",
    "predicted_ug_per_ml = predicted_ug_per_ml.reset_index()\n",
    "#convert all to strings\n",
    "predicted_ug_per_ml['index'] = predicted_ug_per_ml['index'].astype(str)\n",
    "print(predicted_ug_per_ml)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "######################### convert ug/ml to mg/ml\n",
    "# grab the raw values\n",
    "predicted_mg_per_ml = predicted_ug_per_ml[['Rep1','Rep2','Rep3']]\n",
    "# convert\n",
    "predicted_mg_per_ml = predicted_mg_per_ml/1000\n",
    "# append index\n",
    "predicted_mg_per_ml['index'] = predicted_ug_per_ml['index']\n",
    "\n",
    "\n",
    "print(predicted_mg_per_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "####################### generate means and stats\n",
    "predicted_mg_per_ml['mg/ml'] = predicted_mg_per_ml.loc[list(predicted_mg_per_ml.index),[\"Rep1\", \"Rep2\",\"Rep3\"]].mean(axis=1)\n",
    "predicted_mg_per_ml['mg/ml SEM'] = predicted_mg_per_ml.loc[list(predicted_mg_per_ml.index),[\"Rep1\", \"Rep2\",\"Rep3\"]].sem(axis=1)\n",
    "\n",
    "print(predicted_mg_per_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "samples_bar_av_df = predicted_mg_per_ml[[\"mg/ml\", \"mg/ml SEM\"]]\n",
    "print(samples_bar_av_df)\n",
    "\n",
    "ax4 = samples_bar_av_df.plot(kind=\"bar\", yerr=\"mg/ml SEM\", legend=False)\n",
    "ax4.set_title(\"Samples Mean Concentrations & SEMs\")\n",
    "ax4.set_ylabel(\"Concentration in Mg/Ml\")\n",
    "ax4.set_xlabel(\"Dilution Factor\")\n",
    "plt.xticks(np.arange(samples_bar_av_df.shape[0]),acceptable_samples_list, rotation=0, fontsize=\"10\")\n",
    "plt.savefig(\"output/Conc_bar.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "############### check is the SEM on the mean of means is too large.\n",
    "\n",
    "\n",
    "#grab all of the replicates\n",
    "checker_set_df = predicted_mg_per_ml[['Rep1', 'Rep2', 'Rep3']]\n",
    "\n",
    "# initalise an empty series\n",
    "checker_set_series = pd.Series(dtype='float64')\n",
    "\n",
    "# go through the replicates and put them in the series\n",
    "for name, values in checker_set_df.iteritems():\n",
    "    checker_set_series = checker_set_series.append(values)\n",
    "\n",
    "# reset the series\n",
    "checker_set_series = checker_set_series.reset_index(drop=True)\n",
    "print('')\n",
    "#print('Compiled Replicates')\n",
    "#print(checker_set_series)\n",
    "print('')\n",
    "\n",
    "# generate the mean and sem\n",
    "checker_mean, checker_sem = (checker_set_series.mean(),checker_set_series.sem())\n",
    "\n",
    "checker_mean_5_percent = checker_mean/20\n",
    "\n",
    "print('Mean of means: ')\n",
    "print(checker_mean)\n",
    "print(' ')\n",
    "print('SEM of means: ')\n",
    "print(checker_sem)\n",
    "print(' ')\n",
    "print('Is the SEM greater than 5% of the Mean?:')\n",
    "print(checker_sem > checker_mean_5_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "############## Is the sem greater than 5% of the mean?\n",
    "# If so: check for outliers.\n",
    "if checker_sem > checker_mean_5_percent:\n",
    "    \n",
    "    ####################################################################################################################\n",
    "    ####################################################################################################################\n",
    "    ############### Start if Greater than BlOCK\n",
    "    \n",
    "    print('SEM is greater and outliers MIGHT have been identified')\n",
    "    \n",
    "    \n",
    "    #################### box plot to identify outlier\n",
    "    plt.boxplot(x=predicted_mg_per_ml['mg/ml'], vert=False)\n",
    "    plt.title(\"Box Plot of Mean Concentrations\")\n",
    "    plt.xlabel(\"Mg/Ml\")\n",
    "\n",
    "    plt.savefig(\"output/Box_plot.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #########################################################\n",
    "    #calculate interquartile range of values in the 'points' column\n",
    "    q75, q25 = np.percentile(predicted_mg_per_ml['mg/ml'], [75 ,25])\n",
    "    \n",
    "    print(' ')\n",
    "    print('q25: '+str(q25))\n",
    "    print(' ')\n",
    "    print('Mean: '+str(checker_mean))\n",
    "    print(' ')\n",
    "    print('q75: '+str(q75))\n",
    "    print(' ')    \n",
    "        \n",
    "    ######### retain values that are within the interquartile range\n",
    "    acceptable_concs = predicted_mg_per_ml.loc[(predicted_mg_per_ml[\"mg/ml\"] >=q25) & (predicted_mg_per_ml[\"mg/ml\"] <=q75)]\n",
    "\n",
    "    print('The concentrations that are retained after outlier filter')\n",
    "    print(' ')\n",
    "    print(acceptable_concs)\n",
    "    print(' ')\n",
    "    \n",
    "\n",
    "    #########################################################\n",
    "    ####   plot a bar chart of the accepted concentrations\n",
    "    \n",
    "    barplot_df = acceptable_concs[['index','mg/ml','mg/ml SEM']]\n",
    "    ax4 = barplot_df.plot(kind=\"bar\", yerr=\"mg/ml SEM\", legend=False)\n",
    "    ax4.set_title(\"Samples Mean Concentrations & SEMs\")\n",
    "    ax4.set_ylabel(\"Concentration in Mg/Ml\")\n",
    "    ax4.set_xlabel(\"Dilution Factor\")\n",
    "    plt.xticks(np.arange(acceptable_concs.shape[0]),acceptable_concs['index'], rotation=0, fontsize=\"10\")\n",
    "    plt.savefig(\"output/Best_concs_bar.png\")\n",
    "    \n",
    "    #############################################################\n",
    "    ##### using the accepted concentrations to generate a consensus concentration and export it.\n",
    "\n",
    "    subsetted = acceptable_concs[['Rep1', 'Rep2', 'Rep3']]\n",
    "\n",
    "    compiled = pd.Series(dtype='float64')\n",
    "\n",
    "    for name, values in subsetted.iteritems():\n",
    "        compiled = compiled.append(values)\n",
    "\n",
    "    compiled = compiled.reset_index(drop=True)\n",
    "    print('')\n",
    "    print('Compiled Replicates')\n",
    "    print(compiled)\n",
    "    print('')\n",
    "    consensus_mean, consensus_sem = (compiled.mean(),compiled.sem())\n",
    "    print('Generated Consensus Concentration:')\n",
    "    print('consensus_mean: '+ str(consensus_mean))\n",
    "    print('consensus_sem: ' + str(consensus_sem))\n",
    "    consensus_num_samples = acceptable_concs.shape[0]\n",
    "    print('Generated from # dilutions: ' + str(consensus_num_samples))\n",
    "    \n",
    "    print(' ')\n",
    "    print('Saving to Consensus_concentration.csv ...')\n",
    "    consensus_printout = pd.DataFrame(data = [[consensus_mean, consensus_sem, consensus_num_samples]], columns=['Consensus_Mean','Consensus_Sem','Calculated_From_#_Dilutions'])\n",
    "    consensus_printout.to_csv('output/Consensus_concentration.csv')\n",
    "    \n",
    "    ############## END OF IF Greater than BLOCK\n",
    "    ###################################################################################################################################\n",
    "    ###################################################################################################################################\n",
    "\n",
    "else:\n",
    "    \n",
    "    ####################################################################################################################################\n",
    "    ####################################################################################################################################\n",
    "    ############# Start of IF not Greater BLOCK\n",
    "    \n",
    "    print('SEM is not greater and no outliers have been identified')\n",
    "    \n",
    "    subsetted = predicted_mg_per_ml[['Rep1', 'Rep2', 'Rep3']]\n",
    "\n",
    "    compiled = pd.Series(dtype='float64')\n",
    "\n",
    "    for name, values in subsetted.iteritems():\n",
    "        compiled = compiled.append(values)\n",
    "\n",
    "    compiled = compiled.reset_index(drop=True)\n",
    "    print('')\n",
    "    print('Compiled Replicates')\n",
    "    print(compiled)\n",
    "    print('')\n",
    "    consensus_mean, consensus_sem = (compiled.mean(),compiled.sem())\n",
    "    print('Generated Consensus Concentration:')\n",
    "    print('consensus_mean: '+ str(consensus_mean))\n",
    "    print('consensus_sem: ' + str(consensus_sem))\n",
    "    consensus_num_samples = predicted_mg_per_ml.shape[0]\n",
    "    print('Generated from # dilutions: ' + str(consensus_num_samples))\n",
    "    \n",
    "    print(' ')\n",
    "    print('Saving to Consensus_concentration.csv ...')\n",
    "    consensus_printout = pd.DataFrame(data = [[consensus_mean, consensus_sem, consensus_num_samples]], columns=['Consensus_Mean','Consensus_Sem','Calculated_From_#_Dilutions'])\n",
    "    consensus_printout.to_csv('Consensus_concentration.csv')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
